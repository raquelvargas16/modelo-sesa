{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true
            },
            "source": "# <center>Compute Telemetry Facts</center>\n\nIn this notebook we will see how to compute the trip facts from telemetry points stored in SESA's bucket for raw telemetry. We will load telemetry from January 2019 to September 2019.\n\nFirst, let's load the needed libraries."
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\nSpark Initialization Done! ApplicationId = app-20191126200302-0000\nKERNEL_ID = 5a9ddd59-3021-41c9-8379-b8086764820d\n"
                }
            ],
            "source": "# Spark required imports\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import types\nfrom pyspark.sql import Window\nfrom pyspark.sql.types import *\nimport pyspark.sql.functions as F\nfrom pyspark.sql.functions import when\n\nimport pandas as pd\n\n# Access to IBM Cloud Object Storage\nimport ibmos2spark\n\n# Python Utilities\nfrom datetime import datetime"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Service Credentials"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Load Auxiliary datasets\n\nWe will use the following data sets to determinate the day type and the segment road type."
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": "# Segment types with speed limits\nsegment_type = spark.read\\\n  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n  .option('header', 'true')\\\n  .load(local_cos.url('SegmentType.csv', local_bucket))\n#segment_type.show(5)\n\nferiados = spark.read\\\n  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n  .option('header', 'true')\\\n  .load(local_cos.url('Feriados.csv', local_bucket))\nferiados = feriados.withColumnRenamed(\"A\u00f1o\",\"Year\")\nferiados = feriados.withColumnRenamed(\"Fecha Real\",\"Fecha_Feriado\")\nferiados = feriados.select('Year','Feriado','Fecha',F.unix_timestamp(\"Fecha_Feriado\",\"dd/MM/yyyy\").cast(TimestampType()).alias(\"Fecha_Feriado\"))\nferiados = feriados.withColumn(\"Fecha_Feriado\", feriados.Fecha_Feriado.cast(DateType()))\n#feriados.show(5)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Load telemetry by month"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": "period_filter = \"2019-10\"  # Extraer telemetr\u00eda de octubre"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Telemetry Schema"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": "telemetry_raw_schema = StructType([\n    StructField(\"DeviceId\", LongType(), False),\n    StructField(\"Imei\", StringType(), False),\n    StructField(\"Latitude\", DoubleType(), False),\n    StructField(\"Longitude\", DoubleType(), False),\n    StructField(\"Altitude\", DoubleType(), False),\n    StructField(\"Heading\", DoubleType(), False),\n    StructField(\"QPoint\", StringType(), False),\n    StructField(\"Speed\", DoubleType(), False),\n    StructField(\"TripID\", LongType(), False),\n    StructField(\"MessageTime\", TimestampType(), False),\n    StructField(\"GeneratedMessageTime\", TimestampType(), False),\n    StructField(\"SegmentType\", ShortType(), True),\n    StructField(\"Address\", StringType(), False),\n    StructField(\"Mileage\", DoubleType(), False),\n    StructField(\"AlertId\", ShortType(), False),\n    StructField(\"AlertMessage\", StringType(), False),\n    StructField(\"GpsStatus\", StringType(), False),\n    StructField(\"CountNumber\", StringType(), False),\n    StructField(\"CrashCounter\", StringType(), False)\n])"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "cos_bucket_name = \"bkt-prod-sesa-telemetry-raw-data-by-date\"\ncos_file_prefix = \"in.lw.telemetry/dt=\"\n\nrawdf = spark.read.json(cos.url(cos_file_prefix+period_filter+\"*\", cos_bucket_name), schema=telemetry_raw_schema)\n\n#\"{:,}\".format(rawdf.count())|"
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": "#rawdf.count()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The following cell contains some hard filters that need to applied to the telemetry."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Longitude and Latitude maximum and minimum for Ecuador\nminLon=-92.0115860669999108\nmaxLon=-75.2272639579998952\nminLat=-5.0113725789998824\nmaxLat=1.6643740910001550\n\n# TripID == 0 means that the car is parked. For now, we just want the data when the car in in movement.\nrawdf = rawdf.where(F.col(\"TripID\")>0)\n\nrawdf = rawdf.dropDuplicates([\"DeviceId\", \"TripID\",\"Latitude\", \"Longitude\", \"MessageTime\"]) \n\n#Remove inconsistent lat,lon rows\nrawdf = rawdf.filter( rawdf.Longitude.between(minLon, maxLon) & rawdf.Latitude.between(minLat, maxLat))\n\n#remove recors with mileage == 0\nrawdf = rawdf.filter(rawdf.Mileage>0)\n\n#Remove data with low GPS signal and no AlertId\nrawdf = rawdf.where((rawdf.GpsStatus==\"A\") | (rawdf.AlertId.isin(17,35,36,69,70,96,108,109,110,111)))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Months Filter\nstartTime = datetime(2018,9,30,23,59,50)\nendTime = datetime(2019,11,1,4,59,59)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Trip Facts"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "devices_df = rawdf.filter(rawdf.GeneratedMessageTime.between(startTime, endTime))\ndevices_df = devices_df.select(['DeviceId', \n                                'TripID', \n                                'Latitude', \n                                'Longitude', \n                                'MessageTime', \n                                'GeneratedMessageTime', \n                                'Mileage', \n                                'AlertId', \n                                'GpsStatus',\n                                'SegmentType', \n                                'CountNumber'\n                               ])\ndevices_df.columns"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Trips.filter(F.col('TripID') == 15393996).show()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Arreglo para hacer el c\u00e1lculo del CalculatedMessageTime\ntelemetry_facts = devices_df.select(\n    \"DeviceId\",\n    \"TripID\",\n    F.unix_timestamp(F.from_utc_timestamp(\"MessageTime\", \"UTC\")).alias(\"MessageTime\"),\n    F.unix_timestamp(F.from_utc_timestamp(\"GeneratedMessageTime\", \"UTC\")).alias(\"GeneratedMessageTime\"),\n    F.conv(\"CountNumber\",16,10).alias(\"Sequence\"),\n    \"Mileage\",\n    \"SegmentType\",\n    \"AlertId\", \n    F.when(devices_df.AlertId==35, 1).otherwise(F.when(devices_df.AlertId==36, 3).otherwise(2)).alias(\"FrameOrder\")\n)\n\nw1 = Window.partitionBy(\"TripID\",\"DeviceId\").orderBy(\"FrameOrder\",\"Mileage\",\"MessageTime\").rowsBetween(0,1)\ntf_2= telemetry_facts.select(\n    \"DeviceId\",\n    \"TripID\",\n    \"Mileage\",\n    \"MessageTime\",\n    \"GeneratedMessageTime\",\n    (when(F.col(\"AlertId\") == 35,  F.greatest(F.col(\"GeneratedMessageTime\"), F.col(\"MessageTime\")))\n    .when(F.col(\"AlertId\") == 36,  F.least(F.col(\"GeneratedMessageTime\"), F.col(\"MessageTime\")))\n    .otherwise(F.col(\"GeneratedMessageTime\"))).alias(\"CalculatedMessageTime\"),\n    \"SegmentType\",\n    \"AlertId\",\n    \"Sequence\"\n).orderBy(\"TripID\",\"DeviceId\",\"FrameOrder\",\"Mileage\",\"MessageTime\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Trip Sum"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#devices_df = devices_df.join(segment_type, devices_df.SegmentType == segment_type.segment_type)\ndev_df = tf_2.join(segment_type, tf_2.SegmentType == segment_type.segment_type)\ntimeFmt = \"yyyy-MM-dd'T'HH:mm:ss.SSS\"\n\n#win = Window.partitionBy(['DeviceId','TripID']).orderBy('Sequence')\nwin = Window.partitionBy(['DeviceId','TripID']).orderBy(['CalculatedMessageTime', 'Sequence'])\n\ndf_1=dev_df.withColumn('prev_batch', F.lag('speed_limit').over(win)) \\\n    .withColumn('flag', F.when(F.col('speed_limit') == F.col('prev_batch'),0).otherwise(1)) \\\n    .withColumn('batch_order', F.sum('flag').over(win)) \\\n    .drop('prev_batch', 'flag') \\\n    .sort(['DeviceId','TripID','MessageTime','GeneratedMessageTime'])\n\ndf_1=df_1.groupBy(['DeviceId','TripID', \"batch_order\",\"speed_limit\"]).agg(F.max(\"Mileage\").alias('Max_Mil'), F.min(\"Mileage\").alias(\"Min_Mil\"), \n                                                                          F.max('CalculatedMessageTime').alias(\"Max_Time\"), F.min('CalculatedMessageTime').alias(\"Min_Time\"), F.count(\"*\").alias(\"N_Tramas\")).orderBy(['DeviceId','TripID', \"batch_order\"])\n\n\n# BAtc his the flag that anounces change in the speed_limit \nwin = Window.partitionBy(['DeviceId','TripID']).orderBy('batch_order')\n\ndf_2 = df_1.withColumn('maxMileage_prevST', F.lag('Max_Mil').over(win))\\\n        .withColumn('maxTime_prevST', F.lag('Max_Time').over(win))\\\n        .withColumn('speed_limitDistance', F.when(F.col('maxMileage_prevST').isNull(),F.abs(F.col('Max_Mil') - F.col('Min_Mil'))).otherwise(F.abs(F.col('Max_Mil') - F.col('maxMileage_prevST'))))\\\n        .withColumn('speed_limitDuration', F.when(F.col('maxTime_prevST').isNull(),F.abs(F.col('Max_Time') - F.col('Min_Time')) )\\\n                    .otherwise(F.abs(F.col('Max_Time') - F.col('maxTime_prevST'))))\n\ntrip_facts=df_2.groupBy(['DeviceId','TripID', \"speed_limit\"]).agg(F.sum(\"N_tramas\").alias(\"N_tramas\"), \n                                                                  F.sum(\"speed_limitDistance\").alias(\"DistanciaRecorrida\"),\n                                                                  F.sum(\"speed_limitDuration\").alias(\"DuracionRecorrida\")).orderBy(['DeviceId','TripID'])\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#Order by other MT, GM, or CODE\n\ndevices_df = devices_df.join(segment_type, devices_df.SegmentType == segment_type.segment_type)\n\ntimeFmt = \"yyyy-MM-dd'T'HH:mm:ss.SSS\"\n\nwin = Window.partitionBy(['DeviceId','TripID']).orderBy('MessageTime','GeneratedMessageTime')\n\n#batch_order column is to group CODE2 as per the ordered timestamp\ndf_1=devices_df.withColumn('prev_batch', F.lag('speed_limit').over(win)) \\\n    .withColumn('flag', F.when(F.col('speed_limit') == F.col('prev_batch'),0).otherwise(1)) \\\n    .withColumn('batch_order', F.sum('flag').over(win)) \\\n    .drop('prev_batch', 'flag') \\\n    .sort(['DeviceId','TripID','MessageTime','GeneratedMessageTime'])\n\ndf_1=df_1.groupBy(['DeviceId','TripID', \"batch_order\",\"speed_limit\"]).agg(F.max(\"Mileage\").alias('Max_Mil'), F.min(\"Mileage\").alias(\"Min_Mil\"), F.max('MessageTime').alias(\"Max_Time\"), F.min('MessageTime').alias(\"Min_Time\"), F.count(\"*\").alias(\"N_Tramas\")).orderBy(['DeviceId','TripID', \"batch_order\"])\n\nwin = Window.partitionBy(['DeviceId','TripID']).orderBy('batch_order')\ndf_2 = df_1.withColumn('maxMileage_prevST', F.lag('Max_Mil').over(win))\\\n        .withColumn('maxTime_prevST', F.lag('Max_Time').over(win))\\\n        .withColumn('speed_limitDistance', F.when(F.col('maxMileage_prevST').isNull(),F.col('Max_Mil') - F.col('Min_Mil')  ).otherwise(F.col('Max_Mil') - F.col('maxMileage_prevST')))\\\n        .withColumn('speed_limitDuration', F.when(F.col('maxTime_prevST').isNull(),(F.unix_timestamp(F.col('Max_Time'), format=timeFmt) - F.unix_timestamp(F.col('Min_Time'), format=timeFmt)) )\\\n                    .otherwise((F.unix_timestamp(F.col('Max_Time'), format=timeFmt) - F.unix_timestamp(F.col('maxTime_prevST'), format=timeFmt))))\n\ntrip_facts=df_2.groupBy(['DeviceId','TripID', \"speed_limit\"]).agg(F.sum(\"N_tramas\").alias(\"N_tramas\"), F.sum(\"speed_limitDistance\").alias(\"DistanciaRecorrida\"),F.sum(\"speed_limitDuration\").alias(\"DuracionRecorrida\")).orderBy(['DeviceId','TripID'])"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "trip_facts.printSchema()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "trip_facts = trip_facts.withColumn('Distance_LV50', when(F.col(\"speed_limit\")== 50, F.col(\"DistanciaRecorrida\")).otherwise(0))\ntrip_facts = trip_facts.withColumn('Duracion_LV50', when(F.col(\"speed_limit\")== 50, F.col(\"DuracionRecorrida\")).otherwise(0))\ntrip_facts = trip_facts.withColumn('Distance_LV70', when(F.col(\"speed_limit\")== 70, F.col(\"DistanciaRecorrida\")).otherwise(0))\ntrip_facts = trip_facts.withColumn('Duracion_LV70', when(F.col(\"speed_limit\")== 70, F.col(\"DuracionRecorrida\")).otherwise(0))\ntrip_facts = trip_facts.withColumn('Distance_LV80', when(F.col(\"speed_limit\")== 80, F.col(\"DistanciaRecorrida\")).otherwise(0))\ntrip_facts = trip_facts.withColumn('Duracion_LV80', when(F.col(\"speed_limit\")== 80, F.col(\"DuracionRecorrida\")).otherwise(0))\ntrip_facts = trip_facts.withColumn('Distance_LV90', when(F.col(\"speed_limit\")== 90, F.col(\"DistanciaRecorrida\")).otherwise(0))\ntrip_facts = trip_facts.withColumn('Duracion_LV90', when(F.col(\"speed_limit\")== 90, F.col(\"DuracionRecorrida\")).otherwise(0))\ntrip_facts = trip_facts.withColumn('Distance_LV100', when(F.col(\"speed_limit\")== 100, F.col(\"DistanciaRecorrida\")).otherwise(0))\ntrip_facts = trip_facts.withColumn('Duracion_LV100', when(F.col(\"speed_limit\")== 100, F.col(\"DuracionRecorrida\")).otherwise(0))\ntrip_facts = trip_facts.groupby('DeviceId','TripID').agg(F.max(\"N_tramas\").alias(\"N_tramas\"), F.sum(\"DistanciaRecorrida\").alias(\"DistanciaST\"), F.sum(\"DuracionRecorrida\").alias(\"DuracionST\"), \n                                            F.sum(\"Distance_LV50\").alias(\"Dist_50\"), F.sum(\"Duracion_LV50\").alias(\"Dur_50\"), F.sum(\"Distance_LV70\").alias(\"Dist_70\"), \n                                            F.sum(\"Duracion_LV70\").alias(\"Dur_70\"), F.sum(\"Distance_LV80\").alias(\"Dist_80\"), F.sum(\"Duracion_LV80\").alias(\"Dur_80\"),\n                                            F.sum(\"Distance_LV90\").alias(\"Dist_90\"), F.sum(\"Duracion_LV90\").alias(\"Dur_90\"), F.sum(\"Distance_LV100\").alias(\"Dist_100\"), F.sum(\"Duracion_LV100\").alias(\"Dur_100\")\n                                           )"
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": "#trip_facts.write.parquet(local_cos.url(\"TF_V5_TripFacts\"+period_filter , local_bucket), mode = 'overwrite')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Start and End of Trips variables\n\nThe following cell are used to calculate the distance and duration of the trip."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# list of feriados\nferiados=feriados.withColumn(\"Unix_Feriado\", F.unix_timestamp(\"Fecha_Feriado\")) \nlistFeriado=feriados.toPandas()[\"Unix_Feriado\"].values.tolist()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "format = \"yyyy-MM-dd HH:mm:ss\"\n\nStart_Trips = devices_df.filter(devices_df.AlertId==35).select(\"DeviceId\", \"TripID\", F.greatest(\"GeneratedMessageTime\", \"MessageTime\").alias(\"CalculatedMessageTime\"), 'Mileage' ,'Latitude', \"Longitude\")\\\n    .selectExpr(\"DeviceId\", \"TripID\", \"CalculatedMessageTime as StartCalculatedMessageTime\", 'Mileage as StartMileage', 'Latitude as Latitude_ON', \"Longitude as Longitude_ON\")\n\n# Day time of the start of the trip\nStart_Trips = Start_Trips.withColumn(\"EC_Time_ON\", F.from_utc_timestamp(Start_Trips.StartCalculatedMessageTime, \"Etc/GMT+5\"))\n\n# Holiday, work day, or weekend the start of the trip\nStart_Trips = Start_Trips.withColumn(\"tiempo_1\", F.unix_timestamp(Start_Trips.EC_Time_ON.cast(DateType())))\nStart_Trips = Start_Trips.withColumn(\"Start_Holiday\",F.when(Start_Trips.tiempo_1.isin(listFeriado),\"Holiday\").otherwise(F.when(F.date_format('EC_Time_ON', 'u') <= 5, \"Weekday\").otherwise(\"Weekend\")))\n#Start_Trips = Start_Trips.withColumn(\"Start_DayWeek\", F.date_format('EC_Time_ON', 'u'))\nStart_Trips = Start_Trips.drop(\"tiempo_1\")"
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [],
            "source": "#Start_Trips.write.parquet(local_cos.url(\"TF_V5_StartTrips\"+period_filter , local_bucket), mode = 'overwrite')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Finish_Trips = devices_df.filter(devices_df.AlertId==36).select(\"DeviceId\", \"TripID\", F.least(\"GeneratedMessageTime\", \"MessageTime\").alias(\"FinishCalculatedMessageTime\"), 'Mileage','Latitude', \"Longitude\")\\\n    .selectExpr(\"DeviceId\", \"TripID\", \"FinishCalculatedMessageTime as FinishCalculatedMessageTime\", 'Mileage as FinishMileage', 'Latitude as Latitude_OFF', \"Longitude as Longitude_OFF\")\n\n# Day time of the end of the trip\nFinish_Trips = Finish_Trips.withColumn(\"EC_Time_OFF\", F.from_utc_timestamp(Finish_Trips.FinishCalculatedMessageTime, \"Etc/GMT+5\"))\nFinish_Trips = Finish_Trips.withColumn(\"Time\",F.split(F.split(\"EC_Time_OFF\", \" \")[1],\":\")[0])\nFinish_Trips = Finish_Trips.withColumn(\"DayTime\",F.when(F.col(\"Time\").between(6,8),'Manana 6-9').otherwise(F.when(F.col(\"Time\").between(9,11),'Manana 9-12').otherwise(F.when(F.col(\"Time\").between(12,14),'Tarde 12-15').\\\n                                      otherwise(F.when(F.col(\"Time\").between(15,17),'Tarde 15-18').otherwise(F.when(F.col(\"Time\").between(18,20),'Noche 18-21').otherwise(F.when(F.col(\"Time\").between(21,23),'Noche 21-24').\\\n                                      otherwise(F.when(F.col(\"Time\").between (0,2),'Madrugada 0-3').otherwise('Madrugada 3-6'))))))))\n#Finish_Trips = Finish_Trips.withColumn(\"FinishDaytime\",F.when(F.split(F.split(\"EC_Time_OFF\", \" \")[1],\":\")[0].between(6, 18), \"Diurno\").otherwise(\"Nocturno\"))\n\n# Holiday, work day, or weekend the end of the trip\nFinish_Trips = Finish_Trips.withColumn(\"tiempo_1\", F.unix_timestamp(Finish_Trips.EC_Time_OFF.cast(DateType())))\nFinish_Trips = Finish_Trips.withColumn(\"DayType\",F.when(Finish_Trips.tiempo_1.isin(listFeriado),\"Weekend\").otherwise(F.when(F.date_format('EC_Time_OFF', 'u') <= 5, \"Weekday\").otherwise(\"Weekend\")))\nFinish_Trips = Finish_Trips.withColumn(\"DayWeek\", F.date_format('EC_Time_OFF', 'u'))\nFinish_Trips = Finish_Trips.withColumn(\"Month\", F.date_format('EC_Time_OFF', 'M'))\nFinish_Trips = Finish_Trips.withColumn(\"Date\", F.date_format('EC_Time_OFF', 'dd-MM-yyyy'))\nFinish_Trips = Finish_Trips.drop(\"tiempo_1\", \"Time\")"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Finish_Trips.printSchema()"
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [],
            "source": "#Finish_Trips.write.parquet(local_cos.url(\"TF_V5_FinishTrips\"+period_filter , local_bucket), mode = 'overwrite')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Join datasets \nStartEndTrips = Start_Trips.join(Finish_Trips, [\"DeviceId\", \"TripID\"], \"inner\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Distance"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "StartEndTrips = StartEndTrips.withColumn(\"Dist_km\", StartEndTrips.FinishMileage - StartEndTrips.StartMileage)\nStartEndTrips = StartEndTrips.filter((F.col(\"Dist_km\")>0.3) & (F.col(\"Dist_km\") < 1140))\nStartEndTrips = StartEndTrips.drop(\"StartMileage\",\"FinishMileage\", 'Start_Holiday', 'Finish_Holiday')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Duration"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "timeDiff = (F.unix_timestamp(StartEndTrips.FinishCalculatedMessageTime, format=timeFmt)\n            - F.unix_timestamp(StartEndTrips.StartCalculatedMessageTime, format=timeFmt))\n\nStartEndTrips = StartEndTrips.withColumn(\"Duration_s\", timeDiff)\n\n# time greater than 3 minutes and less than 12 hours\nStartEndTrips = StartEndTrips.filter((F.col(\"Duration_s\")> 180) & (F.col(\"Duration_s\") < 43200))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Trips = trip_facts.join(StartEndTrips, [\"DeviceId\", \"TripID\"], \"inner\")"
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {
                "scrolled": false
            },
            "outputs": [],
            "source": "#Trips.orderBy(\"DeviceId\", \"TripID\").show()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "Trips.printSchema()"
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [],
            "source": "#Trips.withColumn('Resta', F.col(\"Dist_km\") - F.col(\"DistanciaST\")).orderBy('Resta', ascending = False).show()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Trips.write.parquet(local_cos.url(\"TripFacts_V5_\"+period_filter , local_bucket), mode = 'overwrite')"
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "624095"
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "Trips3 = spark.read.parquet(local_cos.url(\"TripFacts_V5_2019-09\" , local_bucket))\nTrips3.count()"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": "Trips2 = spark.read.parquet(local_cos.url(\"TripFacts_V5_\"+period_filter , local_bucket))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Mahalanobis\n### Fuctions to remove outliers with Mahalanobis distance"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "647525"
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "Trips2.count()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#convertir a pandas dataframe\ndatos_pd = Trips2.toPandas()\nprint('Done')\ndatos_pd.shape"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "import numpy as np\nfrom scipy.stats import chi2\n\ndef maha_dist(df):\n    mean = df.mean()\n    S_1 = np.linalg.inv(df.cov())\n\n    def fun(row):\n        A = np.dot((row.T - mean), S_1)\n        return np.dot(A, (row - mean))\n    df[\"MAH_dist\"] = df.apply(fun, axis=1)\n\n    return df\n\ndef remove_outl(df, cols = ['Dist_km', 'Duration_h', 'DistanciaST', 'DuracionST_h']):\n    try:\n        if df.shape[0]>30:\n            df = df.sort_values(by=\"TripID\")\n            MahalaDF_SESA_PD = df[cols]\n            MahalaDF_SESA_PD = maha_dist(MahalaDF_SESA_PD[cols])\n            MahalaDF_SESA_PD[\"TripID\"]= df.TripID\n            MahalaDF_SESA_PD['Prob_SESA'] = 1 - chi2.cdf(MahalaDF_SESA_PD['MAH_dist'], len(cols))\n            MahalaDF_SESA_PD = MahalaDF_SESA_PD[MahalaDF_SESA_PD.Prob_SESA>0.001]\n            df = df[df.TripID.isin(MahalaDF_SESA_PD.TripID)]\n            return df\n        else:\n            print(\"Not enough trips to perform outlier detection\")\n    except:\n        print(\"Something went wrong. Check there is a TripID identifier.\")"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#remove outliers\ndatos_clean = remove_outl(datos_pd, cols=['Dist_km', 'Duration_h', 'DistanciaST', 'DuracionST_h'])\ndatos_clean.shape"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "pd.set_option('float_format', '{:f}'.format)\ndatos_clean.loc[datos_clean.Duration_h<datos_clean.DuracionST_h,[ 'Duration_h', 'DistanciaST',\n       'DuracionST_h', 'Dur_50_h', 'Dur_70_h', 'Dur_80_h', 'Dur_90_h',\n       'Dur_100_h']].describe()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "trips_clean_spark = sqlContext.createDataFrame(datos_clean)\n#project.save_data(\"TF_clean_jun_jul_agos.csv\", datos_clean.to_csv(index=False, header = True), overwrite=True)\n#Save cleaned trip facts\nname = \"TripFacts_V5_clean\"+period_filter\ntrips_clean_spark.write.parquet(path=local_cos.url(name, local_bucket), mode=\"overwrite\", compression=\"none\")\nprint(\"Done\")"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}